<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Yu Group - Research</title>
<style type="text/css">
.MainTitle {
	font-family: Georgia, Times New Roman, Times, serif;
	font-size: large;
	color: #999 !important;
	text-decoration: none;
}
.MainTitleBig {
	font-size: xx-large;
	font-family: Georgia, "Times New Roman", Times, serif;
	text-decoration: none;
	color: #999 !important;
}
.Category {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: large;
	font-weight: bold;
	color: #999 !important;
	text-align: center;
	overflow: hidden;
	text-decoration: none;
}
.CategorySmall {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: small;
	font-weight: bold;
	color: #999 !important;
	text-align: center;
	text-decoration: none;
}
.Description {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	font-weight: bold;
	color: #666;
	text-align: center;
}
.DescriptionLeft {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	font-weight: bold;
	color: #666;
	text-align: left;
}
.DescriptionPpl {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: small;
	font-style:italic;
	color: #666;
	text-align: left;
}
.DescriptionRes {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	color: #888;
	text-align: left;
}
.Names {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	color: #666;
	text-align: center;
}
.Names2 {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: small;
	font-weight:bold;
	color: #666;
	text-align: left;
	vertical-align:text-top;
}
.NamesLeft {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	color: #666;
	text-align: left;
}
.Titles {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: medium;
	font-weight:bold;
	color: #666;
	text-align: left;
}
.TitlesLarge {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: large;
	font-weight:bold;
	color: #666;
	text-align: left;
}
.superscript {
	font-size:xx-small; 
	vertical-align:super;
} 
a:link {
	color: #900;
}
a:visited {
	color: #900;
}
a:hover {
	text-decoration: none;
	color: #333;
}
a:active {
	text-decoration: none;
	color: #EDEDED;
	font-family: Georgia, "Times New Roman", Times, serif;
}
</style>
</head>


<body>
<table width="automatic" height="automatic" border="0">
	<tr>
		<td valign="top">
			<table width="214" border="0">
              <tr>
                <td height="100">
                </td>
              </tr>
			  <tr>
			    <td width="208" height="92" align="center"><h2 class="MainTitle"><a href="http://www.stat.berkeley.edu/~yugroup/" class="MainTitle"><span class="MainTitleBig">YU</span> GROUP</a></h2></td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
			  <tr>
			    <td class="Category">| <a href="http://www.stat.berkeley.edu/~yugroup/people/" class="Category">PEOPLE</a> |</td>
			  </tr>
			    <tr>
			      <td class="Category">&nbsp;</td>
			    </tr>
			    <tr>
			    <td class="Category">| <a href="http://www.stat.berkeley.edu/~yugroup/research/" class="Category">RESEARCH</a> |</td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
              <tr>
			    <td class="Category">| <a href="http://www.stat.berkeley.edu/~yugroup/publication/" class="Category">PUBLICATIONS </a>|</td>
			  </tr>
			    <tr>
			      <td class="Category">&nbsp;</td>
			    </tr>
                <tr>
			    <td class="Category">| <a href="http://www.stat.berkeley.edu/~yugroup/downloads/" class="Category">DOWNLOADS</a> |</td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
			  <tr>
			    <td class="Category">| <a href="http://www.stat.berkeley.edu/~yugroup/memo/" class="Category">MEMOS</a> |</td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
              <tr>
			    <td>&nbsp;</td>
			  </tr>
			    <tr>
			    <td height="28" class="CategorySmall"><a href="http://www.stat.berkeley.edu/~yugroup/contact" class="CategorySmall">CONTACT + PHOTOS</a></td>
			  </tr>
			  <tr>
			    <td>&nbsp;</td>
			  </tr>
			</table>
		</td>
		<td>
		<table width="automatic" border="0">
		  <tr>
		    <td width="50">&nbsp;</td>
		    <td width="50">&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td width="50">&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td colspan="3" class="TitlesLarge">Research Overview</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="NamesLeft"><p>We focus on both <a href="#core">core</a> and <a href="#inter">interdisciplinary</a> statistical research.
Our current research covers statistical machine learning (theory and algorithms) and solving data problems from diverse fields such as remote sensing, sensor networks, neuroscience, document query expansion, and robust speech recognition.
Our core statistical research provides needed insights on cutting-edge topics in statistical machine learning such as sparse modeling (e.g., Lasso or L1 penalized Least Squares) for interpretable models and spectral clustering for social networks: both for high dimensional data.
Our algorithmic/methodological developments include BLasso, Spore, SS-CV, and structured sparsity through CAP and path penalties.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		    <tr>
		    <td>&nbsp;</td>
		    <td colspan="3" class="TitlesLarge"><a name="inter" id="inter">Interdisciplinary Research</a></td>
		    <td>&nbsp;</td>
		  </tr>
          	  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		      <td>&nbsp;</td>
		      <td colspan="3">&nbsp;</td>
		      <td>&nbsp;</td>
		  </tr>
		    <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="neuro" id="neuro">Neuroscience: Understanding Visual Pathway</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>The volume and quality of data recorded from the brain are constantly
increasing, giving us a better view of mental processes. We collaborate
with neuroscience labs, primarily <a href="www.gallantlab.org">the Gallant lab</a>, to
develop methodology for analyzing such data. We focus on understanding
human vision by studying the representation of images and videos in the
early visual areas. These experiments are great examples for modern
statistical work: both the treatment (a video, or sequence of images) and
the response (continuous brain-scans, or multiple electrodes) are
high-dimensional structured objects. We develop principled methods to
relate the stimuli and responses for both prediction and interpretation
purposes. These include, among others, methods for supervised
feature-extraction; high-dimensional (and semi-parametric) regression
models relating the features to neural activity; and methods to aggregate
information across multiple responses.  Our collaboration on
reconstructing visual experiences from fMRI signals has gained some public
interest, for example <a href="http://www.economist.com/node/21534748">the Economist</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://www.stat.berkeley.edu/~yuvalb/YuvalWeb/Home.html" target="_new">Yuval Benjamini</a>, <a href="http://www.di.ens.fr/~mairal/index_eng.php" target="_new">Julien Mairal</a>, <a href="http://www.stat.berkeley.edu/~hwli/" target="_new">Hongwei Li</a>, <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
          <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="aod">Remote Sensing: Aerosol Retrieval at High (km) Resolution and Cloud Detection Based on Multi-Angle Satellite (MISR) Images</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>Atmospheric aerosols can cause serious damage to human health and life expectancy.  Using the radiances observed by NASA's Multi-angle Imaging SpectroRadiometer (MISR), the current MISR operational algorithm retrieves Aerosol Optical Depth (AOD) at a spatial resolution of 17.6 x 17.6 km<sup>2</sup>. To assist research on aerosols' impact on public health, especially in highly-populated urban areas, we retrieve AOD at km-resolution based on MISR data.  Our algorithms take advantage of AOD's spatial smoothness and consider beyond the MISR's fixed choices of both AOD values and aerosol mixing vectors.  Based on case studies in the greater Beijing area, we show that a finer resolution retrieval can improve the accuracy and coverage of remotely-sensed aerosol retrievals, as well as our understanding of the spatial and seasonal behaviors of aerosols.  This improvement is particularly important during high-AOD events, which often indicate severe air pollution.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://taesupmoon.com/" target="_new">Taesup Moon</a>, <a href="http://www.stat.berkeley.edu/~yqwang/" target="_new">Yueqing Wang</a>,  <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
          
          <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="brid">Bridge Structure Model Estimation Through Sparse Modeling</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>Advances in Wireless Sensor Networks (WSN) technology have provided promising possibilities in detecting a change in the state of a structure. The natural vibration properties of the structure are often estimated using a multivariate AR model, which requires the computation of the lagged covariance between the measurements in all nodes. The resulting volume of data transmission causes significant latency due to the low data bandwidth of WSNs and the high transmission energy cost. This project uses sparse modeling ideas to tackle the modal estimation problem. We introduce a set of sparsity contraints to the estimation of the AR model. Such restrictions significantly reduce the volume of data owing through the WSN thus reducing the latency in obtaining modal parameters and extending the battery lifetime of the WSN. Stabilisation diagrams are compared for the restricted and full AR models fitted using both simulated and real data collected from a WSN deployed on the Golden Gate Bridge. These stabilisation diagrams show that the estimated modes using the restricted AR models are of comparable quality to that of the full AR model while substantially reducing the volume of transmitted data.</p></td>
		    <td></td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://mypage.iu.edu/~gvrocha/" target="_new">Guilherme Rocha</a>, <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
          
          <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="media">Media and Document Analysis: Automatic and Sparse Query Expansion of Large Document Corpora</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>News media play a significant role in our political and daily lives.
The traditional approach in media analysis to news summarization is labor
intensive.  As the amount of news data grows rapidly, the need is
acute for automatic and scalable methods to aid media analysis
researchers so that they could screen corpora of news articles very
quickly before detailed reading.
To assist in this work, we are developing a general framework for
subject-specific
summarization of document corpora with news articles as a special case.
We use state-of-the art scalable and sparse statistical predictive
frameworks to generate lists of short words/phrases as a summary of a
subject. We have also designed methods to validate these methods with
human surveys to demonstrate that the summarizers capture appropriate
human meaning.   We are using these methods for data visualization,
cross-language information retrieval, and political analysis.  This
project is part of <a href="http://www.eecs.berkeley.edu/~elghaoui/StatNews/">the StatNews project</a>, funded by a Cyber
Discovery and Innovation Grant from the NSF.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://statistics.berkeley.edu/~luke/" target="_new">Luke Miratrix</a>, <a href="http://www.stat.berkeley.edu/~garveshr/" target="_new">Garvesh Raskutti</a>, <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td colspan="3"></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td colspan="3" class="TitlesLarge"><a name="core" id="core">Core Statistical Research</a></td>
		    <td>&nbsp;</td>
		  </tr>
                    	  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"></td>
		    <td>&nbsp;</td>
		  </tr>
                              	  <tr>
		    <td>&nbsp;</td>
		    <td colspan="3">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		            <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="sparse">Sparse Modeling Theory</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>Sparse or parsimonious models are necessary for model interpretability and for ease of communication either among people or via cyberspace. Sparsity thinking can be traced back at least to Occam’s Razor in the 1400’s and has formally been taken into account in statistical model building in the 70’s via model selection criteria such as AIC and BIC. In the last two decades, especially in the last decade, there has been a tremendous surge of research interest in sparse modeling in the mathematical science
communities. This is possibly because massively available data sets make acute the need for sparse models as we have seen in descriptions of our interdisciplinary projects on neuroscience and document summarization. Model (or variable) selection methods such as AIC or BIC are designed to seek sparse models, but incur very expensive computational costs (or are NP-hard) because of
the combinatorial search over 2<sup>p</sup> sub-models when the number of predictors, p, is large. Lasso and its extensions are computationally efficient alternatives to model selection and belong to a class of methods for sparse modeling which is a cutting-edge research area and attracting the best of researchers in statistical machine learning, applied mathematics, and signal processing. When the design aspect is emphasized, sparse modeling is also called compressive sensing. In the past 3 years, a number of journal papers have appeared from our group that involve theoretical analysis of sparse models applied to covariance matrix estimation, generalized linear models, low-rank matrix completion,
high-dimensional non-parametric models, and many others. Additionally, our analysis of sparse methods has been complemented by a number of journal papers that provide sharp lower bound results and a precise characterization of the conditions on data under which our theoretical guarantees hold.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://www.di.ens.fr/~mairal/index_eng.php" target="_new">Julien Mairal</a>, <a href="http://www.stat.berkeley.edu/~garveshr/" target="_new">Garvesh Raskutti</a>, <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>          <tr>
		      <td>&nbsp;</td>
		      <td colspan="3" class="NamesLeft"><a name="spec">Spectral Clustering and High-Dimensional Stochastic Block Model</a></td>
		      <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes">
		    <p>Spectral clustering is a popular and computationally feasible method for discovering the communities (i.e., highly connected units or actors) in networks or graphs. One of the key theoretical question regarding spectral clustering we ask is the following: if there are true communities under a stochastic model (e.g., Stochastic Block Model), does spectral clustering find it? In our analyses, we do not make the manifold assumptions or their extensions, yet bound the number of "misclustered" nodes when we allow the number of clusters in the model to grow with the number of nodes, i.e., in the high-dimensional setting.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="DescriptionRes"><p><a href="http://www.stat.berkeley.edu/~karlrohe/index.html" target="_new">Karl Rohe</a>, <a href="http://www.stat.berkeley.edu/~binyu/" target="_new">Bin Yu</a>.</p></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="Names2"><p>&nbsp;</p></td>
		    <td class="DescriptionRes">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td class="NamesLeft">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		      
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2" class="NamesLeft"></td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		  <tr>
		    <td>&nbsp;</td>
		    <td>&nbsp;</td>
		    <td colspan="2">&nbsp;</td>
		    <td>&nbsp;</td>
		  </tr>
		</table>
		</td>
	</tr>
</table>
</body>
</html>